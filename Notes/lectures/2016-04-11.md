# Filesystem 

### Review
We have a disk that has some sort of geometry (head, cylindar/track, sector)

### THroughput
* Ways to increase throughput: increase rotational speed, increase density, 
* Disk latency: seek-> the arm/head and it varies, the head must wait for the platter to rotate to the start point, and transfer speeds
* You can decrease latency by not using all the tracks and shortening the distance to the starting sector

Ultimately a fs is an array of blocks. The actual getting/putting via a specific interface (iscsi, etc)

### Berkeley Fast FS
On the original UNIX fs, because of the small FS blocks (of 512 B) caused a 20 KiB/s max which is smaller than 2 MiB max expected. Also noted that consecutive blocks need to be close on disk, since you prefetch (up to 16 blocks). Also noted that inodes are far from data. This means you are bouncing back and forth between inodes and files (poor spacial locality). 
* Increased block size. 
* To address far away inodes, you have cylindar groups where each cylindar has a super block, inodes, and data blocks. The superblock is duplicated across the groups. Sacrificed a little space for spacial locality. You also get groups that can be saturated by large files

### Log Structured FS
* Rosenblum -> made VMware! 
* How to increase access to disk drives. 
* Memory and cache sizes are growing, so reads will be increasingly satisfied by cache, so read performance is less important than write performance. Likewise, most disk accesses are writes in general (not all workloads, but yes) So you can optimize for the common case. 
    * Faster writes, similar reads, and faster crashes
* General focus
    * info is spread around, so bad for small reads and writes
    * Synchronous writes meaning processes are blocking on IO completion
    * The solution however is to bundle writes (elevator?) meaning delaying writes so you have large write extents. 
* Implementation issues for bundling writes
    * You need to have a log of the writes. In this log, you have several blocks that get freed/removed and dirty. When reaching the end of the log, either compact or make a list of the empty blocks which prevents it from being continuous space. 
    * To get over this, instead use log segments where you compact only to create free segments instead of a whole thing of compacted
* Also noted that data either long lived or short lived so behave different depending on short or long lived pieces 
* FOr faster crashing, journaling allows fast meta data saving to prevent grossly long fsck. 
* CISC vs RISC -> reduced instruction set, but the numbers of registers increased (all the stuff is done in registers) for RISC

# Ideas
Graph of inodes? 
