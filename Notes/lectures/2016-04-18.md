# Distributed Systems

### Overview
You have a system that communicates over a medium to another system to handle the task. Why? Cost:
you can have multiple cheap hardware nodes rather than a power tank. You can have high availability.
If one node breaks, another can pick up the work/reproduce the data. You can do things in parallel
if you need to break down processing.  

How do you implement these? You can make a shared memory processor. Work is sent across CPUs via 
shared memory cache and accessed via LOADs and STOREs. Distributed systems exchange information via
some sort of networked communication. Likewise, you have have message queues to pass messages back
and forth.  

Amdahl's Law: Parallel speed up: concept: 
* Speed up for n processors = Time something takes on one over time it takes for all. For example, 
If the Speed up for 2 processors (S2) is perfect, then you have the time it takes for 1 CPU double 
the time it takes for 2 CPUs. Or 1 = 2/1 (Sn = T1/Tn). 
* Likewise, you have code that is inherently sequential and a part that is parallel. For the time
required for execution (T1), the maximum speed up you can have can not be sped faster than the 
inherenly sequential code. So S_inf = T1/S. When s = 10%, S_inf = 10. This is also approaching
infinity (count of nodes). 
* This is how hadoop works. The map reduce squashes the sequential aspect.  

### Lamport Clock
* In a distrubuted system, you do not have a global clock. 
* However, you can have causality or a sequence of actions. You can order events, but you can not
time them. __Corolarry__ It is impossible to tell the difference between a node that is dead and
one that is arbitrarily delayed. 

### Network-Oriented OS
Users are aware of the boundaries of networking (this is evident in needing to use ssh/ftp/etc to 
communicate across nets). For distributed systems, users should not be aware of the multiplicity
of system. Likewise, data migration is transparent and compute migrations. IE, users could move 
between physical workstations and work on the same processes on any of them. 

##### Sprite OS
Features:
* Kernel to kernel RPC
    * The filesystem was distributed and you had network transparency. You have to know, but with the ditrbuted fs, you do not need to know where it is at
    * A syscall may need to exexute on a different machine. Processes have a home node that contains the information. The migrations still occurs vua ROC. 
    * Here, the caller will call a stub that assembles the parameters, which then calls the RPC stuff. This process is reversed for the client. 
    * Calls are implemented in RPC. So kernels can tell other kernels what to do. 
* Prefix Tables
    * Instead of indoes and a hierarchy, you have prefixes which has the file prefix, the server it is on, and a token where it is at.  
* Client & Server caching
    * cache all the things
* Virtual Memory used files
    * Currently you have a divided memory space where parts are assigned to kernel, a heap, etc. In sprite, you have this areas, except the dynamic memory is shared by the os is private
* Guarentees with process migration
    * For interrupts you have to parallelize them especailly with locking. You still have asynchronous and split between top and bottom halves, but the interrupts are mutlithreaded. It forks the current process
    * Sometimesyou have a thread / device. 
